{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Self-Driving Car Engineer Nanodegree\n",
    "\n",
    "\n",
    "## Project: Advanced Lane Finding \n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#importing some useful packages\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "from collections import deque\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Useful functions from course\n",
    "The great thing about this project was that most of the code was already provided and explained in the lessons. Most of the code works as it is and the only challenging part is tuning the various parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def corners_unwarp(img, nx, ny, mtx, dist):\n",
    "    # Use the OpenCV undistort() function to remove distortion\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    # Convert undistorted image to grayscale\n",
    "    gray = cv2.cvtColor(undist, cv2.COLOR_BGR2GRAY)\n",
    "    # Search for corners in the grayscaled image\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (nx, ny), None)\n",
    "\n",
    "    if ret == True:\n",
    "        # If we found corners, draw them! (just for fun)\n",
    "        cv2.drawChessboardCorners(undist, (nx, ny), corners, ret)\n",
    "        # Choose offset from image corners to plot detected corners\n",
    "        # This should be chosen to present the result at the proper aspect ratio\n",
    "        # My choice of 100 pixels is not exact, but close enough for our purpose here\n",
    "        offset = 100 # offset for dst points\n",
    "        # Grab the image shape\n",
    "        img_size = (gray.shape[1], gray.shape[0])\n",
    "\n",
    "        # For source points I'm grabbing the outer four detected corners\n",
    "        src = np.float32([corners[0], corners[nx-1], corners[-1], corners[-nx]])\n",
    "        # For destination points, I'm arbitrarily choosing some points to be\n",
    "        # a nice fit for displaying our warped result \n",
    "        # again, not exact, but close enough for our purposes\n",
    "        dst = np.float32([[offset, offset], [img_size[0]-offset, offset], \n",
    "                                     [img_size[0]-offset, img_size[1]-offset], \n",
    "                                     [offset, img_size[1]-offset]])\n",
    "        # Given src and dst points, calculate the perspective transform matrix\n",
    "        M = cv2.getPerspectiveTransform(src, dst)\n",
    "        # Warp the image using OpenCV warpPerspective()\n",
    "        warped = cv2.warpPerspective(undist, M, img_size)\n",
    "\n",
    "    # Return the resulting image and matrix\n",
    "    return warped, M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Thesholding Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def abs_sobel_thresh(img, orient='x', thresh_min=0, thresh_max=255):\n",
    "    \n",
    "    # Apply the following steps to img\n",
    "    # 1) Convert to grayscale\n",
    "    # 2) Take the derivative in x or y given orient = 'x' or 'y'\n",
    "    # 3) Take the absolute value of the derivative or gradient\n",
    "    # 4) Scale to 8-bit (0 - 255) then convert to type = np.uint8\n",
    "    # 5) Create a mask of 1's where the scaled gradient magnitude \n",
    "            # is > thresh_min and < thresh_max\n",
    "    # 6) Return this mask as your binary_output image\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Apply x or y gradient with the OpenCV Sobel() function\n",
    "    # and take the absolute value\n",
    "    if orient == 'x':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 1, 0))\n",
    "    if orient == 'y':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 0, 1))\n",
    "    # Rescale back to 8 bit integer\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    # Create a copy and apply the threshold\n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "    # Here I'm using inclusive (>=, <=) thresholds, but exclusive is ok too\n",
    "    binary_output[(scaled_sobel >= thresh_min) & (scaled_sobel <= thresh_max)] = 1\n",
    "\n",
    "    # Return the result\n",
    "    return binary_output    \n",
    "\n",
    "def mag_thresh(img, sobel_kernel=3, mag_thresh=(0, 255)):\n",
    "    \n",
    "    # Apply the following steps to img\n",
    "    # 1) Convert to grayscale\n",
    "    # 2) Take the gradient in x and y separately\n",
    "    # 3) Calculate the magnitude \n",
    "    # 4) Scale to 8-bit (0 - 255) and convert to type = np.uint8\n",
    "    # 5) Create a binary mask where mag thresholds are met\n",
    "    # 6) Return this mask as your binary_output image\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Take both Sobel x and y gradients\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # Calculate the gradient magnitude\n",
    "    gradmag = np.sqrt(sobelx**2 + sobely**2)\n",
    "    # Rescale to 8 bit\n",
    "    scale_factor = np.max(gradmag)/255 \n",
    "    gradmag = (gradmag/scale_factor).astype(np.uint8) \n",
    "    # Create a binary image of ones where threshold is met, zeros otherwise\n",
    "    binary_output = np.zeros_like(gradmag)\n",
    "    binary_output[(gradmag >= mag_thresh[0]) & (gradmag <= mag_thresh[1])] = 1\n",
    "\n",
    "    # Return the binary image\n",
    "    return binary_output\n",
    "\n",
    "def dir_threshold(img, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "    \n",
    "    # Apply the following steps to img\n",
    "    # 1) Convert to grayscale\n",
    "    # 2) Take the gradient in x and y separately\n",
    "    # 3) Take the absolute value of the x and y gradients\n",
    "    # 4) Use np.arctan2(abs_sobely, abs_sobelx) to calculate the direction of the gradient \n",
    "    # 5) Create a binary mask where direction thresholds are met\n",
    "    # 6) Return this mask as your binary_output image\n",
    "\n",
    "    # Grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Calculate the x and y gradients\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # Take the absolute value of the gradient direction, \n",
    "    # apply a threshold, and create a binary image result\n",
    "    absgraddir = np.arctan2(np.absolute(sobely), np.absolute(sobelx))\n",
    "    binary_output =  np.zeros_like(absgraddir)\n",
    "    binary_output[(absgraddir >= thresh[0]) & (absgraddir <= thresh[1])] = 1\n",
    "\n",
    "    # Return the binary image\n",
    "    return binary_output    \n",
    "\n",
    "def hls_select(img, thresh=(0, 255)):\n",
    "    # 1) Convert to HLS color space\n",
    "    # 2) Apply a threshold to the S channel\n",
    "    # 3) Return a binary image of threshold result\n",
    "\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    s_channel = hls[:,:,2]\n",
    "    binary_output = np.zeros_like(s_channel)\n",
    "    binary_output[(s_channel > thresh[0]) & (s_channel <= thresh[1])] = 1\n",
    "    return binary_output\n",
    "\n",
    "def threshold_image(img, s_thresh=(170, 255), sx_thresh=(20, 100)):\n",
    "    img = np.copy(img)\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS).astype(np.float)\n",
    "    l_channel = hls[:,:,1]\n",
    "    s_channel = hls[:,:,2]\n",
    "    # Sobel x\n",
    "    sobelx = cv2.Sobel(l_channel, cv2.CV_64F, 1, 0) # Take the derivative in x\n",
    "    abs_sobelx = np.absolute(sobelx) # Absolute x derivative to accentuate lines away from horizontal\n",
    "    scaled_sobel = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "    \n",
    "    # Threshold x gradient\n",
    "    sxbinary = np.zeros_like(scaled_sobel)\n",
    "    sxbinary[(scaled_sobel >= sx_thresh[0]) & (scaled_sobel <= sx_thresh[1])] = 1\n",
    "    \n",
    "    # Threshold color channel\n",
    "    s_binary = np.zeros_like(s_channel)\n",
    "    s_binary[(s_channel >= s_thresh[0]) & (s_channel <= s_thresh[1])] = 1\n",
    "    # Stack each channel\n",
    "    # Note color_binary[:, :, 0] is all 0s, effectively an all black image. It might\n",
    "    # be beneficial to replace this channel with something else.\n",
    "    color_binary = np.dstack(( np.zeros_like(sxbinary), sxbinary, s_binary))\n",
    "    return color_binary\n",
    "\n",
    "class Line():\n",
    "    def __init__(self):\n",
    "        # was the line detected in the last iteration?\n",
    "        self.detected = False  \n",
    "        # x values of the last n fits of the line\n",
    "        self.recent_xfitted = [] \n",
    "        #average x values of the fitted line over the last n iterations\n",
    "        self.bestx = None     \n",
    "        #polynomial coefficients averaged over the last n iterations\n",
    "        self.best_fit = None  \n",
    "        #polynomial coefficients for the most recent fit\n",
    "        self.current_fit = [np.array([False])]  \n",
    "        #radius of curvature of the line in some units\n",
    "        self.radius_of_curvature = None \n",
    "        #distance in meters of vehicle center from the line\n",
    "        self.line_base_pos = None \n",
    "        #difference in fit coefficients between last and new fits\n",
    "        self.diffs = np.array([0,0,0], dtype='float') \n",
    "        #x values for detected line pixels\n",
    "        self.allx = None  \n",
    "        #y values for detected line pixels\n",
    "        self.ally = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Sliding Window Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def sliding_window_lines(binary_warped):\n",
    "    # Assuming you have created a warped binary image called \"binary_warped\"\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = np.sum(binary_warped[binary_warped.shape[0]/2:,:], axis=0)\n",
    "    # Create an output image to draw on and  visualize the result\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]/2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "    \n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 9\n",
    "    # Set height of windows\n",
    "    window_height = np.int(binary_warped.shape[0]/nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated for each window\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 100\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 50\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "    \n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high = binary_warped.shape[0] - window*window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low),(win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low),(win_xright_high,win_y_high),(0,255,0), 2) \n",
    "        # Identify the nonzero pixels in x and y within the window\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "    \n",
    "    # Concatenate the arrays of indices\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "    \n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds] \n",
    "    \n",
    "    return (leftx, lefty), (rightx, righty), out_img\n",
    "\n",
    "# Pipeline function\n",
    "def detect_lanes_simple(img):\n",
    "    (leftx, lefty), (rightx, righty), out_img = sliding_window_lines(img)\n",
    "    \n",
    "    return leftx, rightx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Lane Detection and Polynomial Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def fit_polynomial(leftpoints, rightpoints):\n",
    "    \"\"\"Fit a second order polynomial to each array of lane points.\"\"\"\n",
    "    left_fit = np.polyfit(leftpoints[1], leftpoints[0], 2)\n",
    "    right_fit = np.polyfit(rightpoints[1], rightpoints[0], 2)\n",
    "    return left_fit, right_fit\n",
    "\n",
    "def generate_plot_fit(src_img, left_fit, right_fit):\n",
    "    # Generate x and y values for plotting\n",
    "    fity = np.linspace(0, src_img.shape[0] - 1, src_img.shape[0])\n",
    "    fit_leftx = left_fit[0] * fity ** 2 + left_fit[1] * fity + left_fit[2]\n",
    "    fit_rightx = right_fit[0] * fity ** 2 + right_fit[1] * fity + right_fit[2]\n",
    "    return fity, fit_leftx, fit_rightx\n",
    "\n",
    "def display_lanes_window(src_img, left_points, right_points, left_fit, right_fit, out_img):\n",
    "    # Generate x and y values for plotting\n",
    "    fity, fit_leftx, fit_rightx = generate_plot_fit(src_img, left_fit, right_fit)\n",
    "\n",
    "    out_img[left_points[1], left_points[0]] = [255, 0, 0]\n",
    "    out_img[right_points[1], right_points[0]] = [0, 0, 255]\n",
    "    plt.imshow(out_img)\n",
    "    plt.plot(fit_leftx, fity, color='yellow')\n",
    "    plt.plot(fit_rightx, fity, color='yellow')\n",
    "    plt.xlim(0, 1280)\n",
    "    plt.ylim(720, 0)\n",
    "    plt.savefig('./output_images/lanedetection_sliding_window.png')\n",
    "    plt.show()\n",
    "    \n",
    "def get_lanes_predicted(img, left_fit, right_fit):\n",
    "    \"\"\"Retrieve lane lines based on existing best guess by get_lanes_window.\"\"\"\n",
    "    # Create an output image to draw on and visualize the result\n",
    "    out_img = np.dstack((img, img, img)) * 255\n",
    "\n",
    "    nonzero = img.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    margin = 100\n",
    "    left_lane_inds = ((nonzerox > (left_fit[0] * (nonzeroy ** 2) + left_fit[1] * nonzeroy + left_fit[2] - margin)) & (\n",
    "        nonzerox < (left_fit[0] * (nonzeroy ** 2) + left_fit[1] * nonzeroy + left_fit[2] + margin)))\n",
    "    right_lane_inds = ((nonzerox > (right_fit[0] * (nonzeroy ** 2) + right_fit[1] * nonzeroy + right_fit[2] - margin)) & (\n",
    "        nonzerox < (right_fit[0] * (nonzeroy ** 2) + right_fit[1] * nonzeroy + right_fit[2] + margin)))\n",
    "\n",
    "    # Again, extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds]\n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    return (leftx, lefty), (rightx, righty), out_img\n",
    "\n",
    "def display_lanes_predicted(img, left_points, right_points, left_fit, right_fit):\n",
    "    # Generate x and y values for plotting\n",
    "    fity, fit_leftx, fit_rightx = generate_plot_fit(img, left_fit, right_fit)\n",
    "\n",
    "    # Create an image to draw on and an image to show the selection window\n",
    "    out_img = np.dstack((img, img, img))*255\n",
    "    window_img = np.zeros_like(out_img)\n",
    "\n",
    "    # Color in left and right line pixels\n",
    "    out_img[left_points[1], left_points[0]] = [255, 0, 0]\n",
    "    out_img[right_points[1], right_points[0]] = [0, 0, 255]\n",
    "\n",
    "    margin = 100\n",
    "    \n",
    "    # Generate a polygon to illustrate the search window area\n",
    "    # And recast the x and y points into usable format for cv2.fillPoly()\n",
    "    left_line_window1 = np.array([np.transpose(np.vstack([fit_leftx-margin, fity]))])\n",
    "    left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([fit_leftx+margin, fity])))])\n",
    "    left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "    right_line_window1 = np.array([np.transpose(np.vstack([fit_rightx-margin, fity]))])\n",
    "    right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([fit_rightx+margin, fity])))])\n",
    "    right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(window_img, np.int_([left_line_pts]), (0,255, 0))\n",
    "    cv2.fillPoly(window_img, np.int_([right_line_pts]), (0,255, 0))\n",
    "    result = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "    plt.imshow(result)\n",
    "    plt.plot(fit_leftx, fity, color='yellow')\n",
    "    plt.plot(fit_rightx, fity, color='yellow')\n",
    "    plt.xlim(0, 1280)\n",
    "    plt.ylim(720, 0)\n",
    "    plt.savefig('./output_images/lanedetection_previous_detection.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Search Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# window settings\n",
    "window_width = 50 \n",
    "window_height = 80 # Break image into 9 vertical layers since image height is 720\n",
    "margin = 100 # How much to slide left and right for searching\n",
    "\n",
    "def window_mask(width, height, img_ref, center,level):\n",
    "    output = np.zeros_like(img_ref)\n",
    "    output[int(img_ref.shape[0]-(level+1)*height):int(img_ref.shape[0]-level*height),max(0,int(center-width/2)):min(int(center+width/2),img_ref.shape[1])] = 1\n",
    "    return output\n",
    "\n",
    "def find_window_centroids(image, window_width, window_height, margin):\n",
    "    \n",
    "    window_centroids = [] # Store the (left,right) window centroid positions per level\n",
    "    window = np.ones(window_width) # Create our window template that we will use for convolutions\n",
    "    \n",
    "    # First find the two starting positions for the left and right lane by using np.sum to get the vertical image slice\n",
    "    # and then np.convolve the vertical image slice with the window template \n",
    "    \n",
    "    # Sum quarter bottom of image to get slice, could use a different ratio\n",
    "    l_sum = np.sum(warped[int(3*warped.shape[0]/4):,:int(warped.shape[1]/2)], axis=0)\n",
    "    l_center = np.argmax(np.convolve(window,l_sum))-window_width/2\n",
    "    r_sum = np.sum(warped[int(3*warped.shape[0]/4):,int(warped.shape[1]/2):], axis=0)\n",
    "    r_center = np.argmax(np.convolve(window,r_sum))-window_width/2+int(warped.shape[1]/2)\n",
    "    \n",
    "    # Add what we found for the first layer\n",
    "    window_centroids.append((l_center,r_center))\n",
    "    \n",
    "    # Go through each layer looking for max pixel locations\n",
    "    for level in range(1,(int)(warped.shape[0]/window_height)):\n",
    "        # convolve the window into the vertical slice of the image\n",
    "        image_layer = np.sum(warped[int(warped.shape[0]-(level+1)*window_height):int(warped.shape[0]-level*window_height),:], axis=0)\n",
    "        conv_signal = np.convolve(window, image_layer)\n",
    "        # Find the best left centroid by using past left center as a reference\n",
    "        # Use window_width/2 as offset because convolution signal reference is at right side of window, not center of window\n",
    "        offset = window_width/2\n",
    "        l_min_index = int(max(l_center+offset-margin,0))\n",
    "        l_max_index = int(min(l_center+offset+margin,warped.shape[1]))\n",
    "        l_center = np.argmax(conv_signal[l_min_index:l_max_index])+l_min_index-offset\n",
    "        # Find the best right centroid by using past right center as a reference\n",
    "        r_min_index = int(max(r_center+offset-margin,0))\n",
    "        r_max_index = int(min(r_center+offset+margin,warped.shape[1]))\n",
    "        r_center = np.argmax(conv_signal[r_min_index:r_max_index])+r_min_index-offset\n",
    "        # Add what we found for that layer\n",
    "        window_centroids.append((l_center,r_center))\n",
    "\n",
    "    return window_centroids\n",
    "\n",
    "window_centroids = find_window_centroids(warped, window_width, window_height, margin)\n",
    "\n",
    "# If we found any window centers\n",
    "if len(window_centroids) > 0:\n",
    "\n",
    "    # Points used to draw all the left and right windows\n",
    "    l_points = np.zeros_like(warped)\n",
    "    r_points = np.zeros_like(warped)\n",
    "\n",
    "    # Go through each level and draw the windows \t\n",
    "    for level in range(0,len(window_centroids)):\n",
    "        # Window_mask is a function to draw window areas\n",
    "        l_mask = window_mask(window_width,window_height,warped,window_centroids[level][0],level)\n",
    "        r_mask = window_mask(window_width,window_height,warped,window_centroids[level][1],level)\n",
    "        # Add graphic points from window mask here to total pixels found \n",
    "        l_points[(l_points == 255) | ((l_mask == 1) ) ] = 255\n",
    "        r_points[(r_points == 255) | ((r_mask == 1) ) ] = 255\n",
    "\n",
    "    # Draw the results\n",
    "    template = np.array(r_points+l_points,np.uint8) # add both left and right window pixels together\n",
    "    zero_channel = np.zeros_like(template) # create a zero color channle \n",
    "    template = np.array(cv2.merge((zero_channel,template,zero_channel)),np.uint8) # make window pixels green\n",
    "    warpage = np.array(cv2.merge((warped,warped,warped)),np.uint8) # making the original road pixels 3 color channels\n",
    "    output = cv2.addWeighted(warpage, 1, template, 0.5, 0.0) # overlay the orignal road image with window results\n",
    " \n",
    "# If no window centers found, just display orginal road image\n",
    "else:\n",
    "    output = np.array(cv2.merge((warped,warped,warped)),np.uint8)\n",
    "\n",
    "# Display the final results\n",
    "plt.imshow(output)\n",
    "plt.title('window fitting results')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Radius of Curvature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def calculate_curvature(image_size, left_x, right_x):\n",
    "    # first we calculate the intercept points at the bottom of our image\n",
    "    left_intercept = self.left_fit[0] * image_size[0] ** 2 + self.left_fit[1] * image_size[0] + self.left_fit[2]\n",
    "    right_intercept = self.right_fit[0] * image_size[0] ** 2 + self.right_fit[1] * image_size[0] + self.right_fit[2]\n",
    "\n",
    "    # Next take the difference in pixels between left and right interceptor points\n",
    "    road_width_in_pixels = right_intercept - left_intercept\n",
    "    assert road_width_in_pixels > 0, 'Road width in pixel can not be negative'\n",
    "\n",
    "    # Since average highway lane line width in US is about 3.7m\n",
    "    # Source: https://en.wikipedia.org/wiki/Lane#Lane_width\n",
    "    # we calculate length per pixel in meters\n",
    "    meters_per_pixel_x_dir = 3.7 / road_width_in_pixels\n",
    "    meters_per_pixel_y_dir = 30 / road_width_in_pixels\n",
    "\n",
    "    # Recalculate road curvature in X-Y space\n",
    "    ploty = np.linspace(0, 719, num=720)\n",
    "    y_eval = np.max(ploty)\n",
    "\n",
    "    # Fit new polynomials to x,y in world space\n",
    "    left_fit_cr = np.polyfit(ploty * meters_per_pixel_y_dir, left_x * meters_per_pixel_x_dir, 2)\n",
    "    right_fit_cr = np.polyfit(ploty * meters_per_pixel_y_dir, right_x * meters_per_pixel_x_dir, 2)\n",
    "\n",
    "    # Calculate the new radii of curvature\n",
    "    left_curverad = ((1 + (2 * left_fit_cr[0] * y_eval * meters_per_pixel_y_dir + left_fit_cr[1]) ** 2) ** 1.5) / \\\n",
    "                    np.absolute(2 * left_fit_cr[0])\n",
    "\n",
    "    right_curverad = ((1 + (2 * right_fit_cr[0] * y_eval * meters_per_pixel_y_dir + right_fit_cr[1]) ** 2) ** 1.5) / \\\n",
    "                     np.absolute(2 * right_fit_cr[0])\n",
    "\n",
    "    # Next, we can lane deviation\n",
    "    calculated_center = (left_intercept + right_intercept) / 2.0\n",
    "    lane_deviation = (calculated_center - image_size[1] / 2.0) * meters_per_pixel_x_dir\n",
    "\n",
    "    return left_curverad, right_curverad, lane_deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Build a Lane Finding Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Camera Calibration\n",
    "Here are the steps of camera calibration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "objp = np.zeros((6*9,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9, 0:6].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('camera_cal/calibration*.jpg')\n",
    "# Step through the list and search for chessboard corners\n",
    "for idx, fname in enumerate(images):\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9,6), None)\n",
    "\n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "        # Draw and display the corners\n",
    "        cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "        write_name = 'output_images/calibrated/' + fname.split(os.sep)[-1]\n",
    "        cv2.imwrite(write_name, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Visualize undistortion\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "ax1.imshow(mpimg.imread('camera_cal/calibration2.jpg'))\n",
    "ax1.set_title('Original Image', fontsize=30)\n",
    "ax2.imshow(mpimg.imread('output_images/calibrated/calibration2.jpg'))\n",
    "ax2.set_title('Calibrated Image', fontsize=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Distortion Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, (img.shape[1], img.shape[0]), None, None)\n",
    "\n",
    "# Test undistortion on an image\n",
    "images = glob.glob('test_images/*.jpg')\n",
    "for idx, fname in enumerate(images):\n",
    "    img = cv2.imread(fname)\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    \n",
    "    dst = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    cv2.imwrite('output_images/undistorted/' + fname.split(os.sep)[-1], dst)\n",
    "\n",
    "# Save the camera calibration result for later use (we won't worry about rvecs / tvecs)\n",
    "calibration_result = {}\n",
    "calibration_result[\"mtx\"] = mtx\n",
    "calibration_result[\"dist\"] = dist\n",
    "\n",
    "# Pipeline function\n",
    "def undistort_image(img):\n",
    "    return cv2.undistort(img, calibration_result[\"mtx\"], calibration_result[\"dist\"], None, calibration_result[\"mtx\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Visualize undistortion\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "ax1.imshow(mpimg.imread('test_images/straight_lines1.jpg'))\n",
    "ax1.set_title('Original Image', fontsize=30)\n",
    "ax2.imshow(mpimg.imread('output_images/undistorted/straight_lines1.jpg'))\n",
    "ax2.set_title('Undistorted Image', fontsize=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Color and Gradient Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "image = mpimg.imread('test_images/test1.jpg')\n",
    "ax1.imshow(image)\n",
    "ax1.set_title('Original Image', fontsize=30)\n",
    "ax2.imshow(threshold_image(image))\n",
    "ax2.set_title('Tresholded Image', fontsize=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Perspective Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def warper(img, src=None, dst=None, inverse=False):\n",
    "\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    if src is None:\n",
    "        src = np.float32(\n",
    "            [[(img_size[0] / 2) - 60, img_size[1] / 2 + 100],\n",
    "            [((img_size[0] / 6) - 10), img_size[1]],\n",
    "            [(img_size[0] * 5 / 6) + 60, img_size[1]],\n",
    "            [(img_size[0] / 2 + 70), img_size[1] / 2 + 100]])\n",
    "    if dst is None:\n",
    "        dst = np.float32(\n",
    "            [[(img_size[0] / 4), 0],\n",
    "            [(img_size[0] / 4), img_size[1]],\n",
    "            [(img_size[0] * 3 / 4), img_size[1]],\n",
    "            [(img_size[0] * 3 / 4), 0]])\n",
    "    \n",
    "    # Given src and dst points, calculate the perspective transform matrix\n",
    "    if not inverse:\n",
    "        M = cv2.getPerspectiveTransform(src, dst)\n",
    "    else: # This is actually the calculation of the inverse matrix, Minv.\n",
    "        M = cv2.getPerspectiveTransform(dst, src)\n",
    "\n",
    "    # Warp the image using OpenCV warpPerspective()\n",
    "    warped = cv2.warpPerspective(img, M, img_size)\n",
    "\n",
    "    # Return the resulting image and matrix\n",
    "    return warped, M\n",
    "\n",
    "# pipeline function\n",
    "src = np.float32([[253, 697],[585,456],[700, 456],[1061,690]])\n",
    "dst = np.float32([[303, 697],[303,0],[1011, 0],[1011,690]])\n",
    "M = cv2.getPerspectiveTransform(src, dst)\n",
    "\n",
    "def warp_image(img, img_size):\n",
    "    return cv2.warpPerspective(img, M, img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "image = mpimg.imread('test_images/straight_lines2.jpg')\n",
    "ax1.imshow(image)\n",
    "ax1.set_title('Original Image', fontsize=30)\n",
    "warped, M = warper(image) \n",
    "ax2.imshow(warped)\n",
    "ax2.set_title('Transformed Image', fontsize=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "\n",
    "## Video Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "left_buffer = deque([], 10)\n",
    "right_buffer = deque([], 10)\n",
    "\n",
    "# Read pickle\n",
    "def process_image(image):\n",
    "    image = np.copy(image)\n",
    "    size = (image.shape[1], image.shape[0])\n",
    "    undistorted_image = undistort_image(image)\n",
    "    warped_image = warp_image(undistorted_image, size)\n",
    "    binary_image = threshold_image(warped_image)\n",
    "    \n",
    "    fit_leftx, fit_rightx = detect_lanes_simple(binary_image)\n",
    "\n",
    "    left_buffer.append(fit_leftx)\n",
    "    right_buffer.append(fit_rightx)\n",
    "    ave_left = np.average(left_buffer, axis=0)\n",
    "    ave_right = np.average(right_buffer, axis=0)\n",
    "\n",
    "    left_curvature, right_curvature, calculated_deviation = calculate_curvature(image.shape, ave_left,\n",
    "                                             ave_right)\n",
    "    curvature_text = 'Left Curvature: {:.2f} m    Right Curvature: {:.2f} m'.format(left_curvature, right_curvature)\n",
    "\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.putText(image, curvature_text, (100, 50), font, 1, (221, 28, 119), 2)\n",
    "\n",
    "    deviation_info = 'Lane Deviation: {:.3f} m'.format(calculated_deviation)\n",
    "    cv2.putText(image, deviation_info, (100, 90), font, 1, (221, 28, 119), 2)\n",
    "\n",
    "    filled_image = self.fill_lane_lines(binary_image, ave_left, ave_right)\n",
    "\n",
    "    merged_image = self.merge_images(filled_image, image)\n",
    "\n",
    "    return merged_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now for the one with the solid yellow lane on the left. This one's more tricky!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "project_output = 'output_videos/project_video.mp4'\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "test_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time test_clip.write_videofile(test_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(project_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "challenge_output = 'output_videos/challenge_video.mp4'\n",
    "clip1 = VideoFileClip(\"challenge_video.mp4\")\n",
    "challenge_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time challenge_clip.write_videofile(challenge_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(challenge_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "harder_challenge_output = 'output_videos/harder_challenge_video.mp4'\n",
    "clip1 = VideoFileClip(\"harder_challenge_video.mp4\")\n",
    "harder_challenge_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time harder_challenge_clip.write_videofile(harder_challenge_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(harder_challenge_output))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
